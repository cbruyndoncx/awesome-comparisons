# Seed-Coder - https://github.com/ByteDance-Seed/Seed-Coder

Lightweight open-source code LLM family from ByteDance Seed trained on 6 trillion tokens. Achieves state-of-the-art performance at 8B scale, surpassing much larger models.

## General Info

### Classification
- AIE/Model

### Version
- 1.0 (2025-06)

### Repo
- https://github.com/ByteDance-Seed/Seed-Coder

### Rating
- -

### Short Description
- Family of lightweight open-source code LLMs (base, instruct, reasoning) trained on 6T tokens from GitHub code, commit histories, and code-related web data, achieving SOTA at 8B scale.

### Description
Seed-Coder is a family of lightweight open-source code language models developed by ByteDance Seed, comprising base, instruct, and reasoning model variants. The pretraining corpus comprises approximately 6 trillion tokens sourced from GitHub code, commit histories, and code-related web data, providing comprehensive coverage of modern software development practices. Despite its relatively compact 8B parameter scale, Seed-Coder achieves state-of-the-art performance among open-source models at this size and even surpasses some much larger models in coding benchmarks. All models in the family are publicly available on Hugging Face, making them accessible for research, fine-tuning, and deployment. The model family represents ByteDance's contribution to open-source AI coding tools, providing an efficient alternative for developers who need strong coding capabilities without requiring massive computational resources.

### Languages
- Any

### Notes
- 6 trillion tokens: Massive training corpus from GitHub code, commits, and code-related web data.
- Lightweight efficiency: Achieves SOTA at 8B scale, surpassing much larger models.
- Model family: Includes base, instruct, and reasoning variants for different use cases.
- Open source: All models publicly available on Hugging Face collection.
- State-of-the-art 8B: Best performance among open-source models at 8B parameter scale.
- Compact deployment: Suitable for resource-constrained environments while maintaining quality.
- ByteDance Seed: Developed by ByteDance's AI research division.
- Research-friendly: Accessible for academic research, fine-tuning, and custom deployments.
- Code-focused training: Specialized corpus emphasizing practical software development.
- Released June 2025 as part of ByteDance's open-source AI strategy.

### Last Update
- 2025-06

## Licensing

### Opensource
- Yes

### License
- MIT
  - Note: Different sources report both MIT and Apache-2.0; verify from official repository

### FreeTrial
- Yes
