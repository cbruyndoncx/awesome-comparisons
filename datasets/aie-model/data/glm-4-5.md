# GLM-4.5 - https://huggingface.co/zai-org/GLM-4.5

Open-source model family from Zhipu AI (Z.ai) unifying reasoning, coding, agentic abilities, and vision. Released August 2025, achieving 64.2% on SWE-bench Verified, surpassing GPT-4.1 and Claude 4 Opus.

## General Info

### Classification
- AIE/Model

### Version
- 4.5 (2025-08)

### Repo
- https://huggingface.co/zai-org/GLM-4.5

### Rating
- -

### Short Description
- Open-source MoE model family with 355B total parameters (32B active) featuring exceptional coding performance, achieving 64.2% on SWE-bench and 80.8% win rate against Qwen3 Coder in real-world challenges.

### Description
GLM-4.5 is an open-source large language model series from Zhipu AI (Z.ai) designed to unify advanced reasoning, coding, agentic abilities, and vision in a single powerful framework. Released in August 2025, the flagship GLM-4.5 model features 355 billion total parameters with 32 billion active parameters, while GLM-4.5-Air offers a more compact design with 106 billion total parameters and 12 billion active parameters. The series demonstrates exceptional coding performance with 64.2% on SWE-bench Verified, surpassing GPT-4.1 (48.6%) and achieving an 80.8% win rate against Qwen3 Coder in real-world coding challenges. The model runs efficiently on just eight Nvidia H20 GPUsâ€”half the hardware of comparable models. Available variants include GLM-4-Flash, GLM-4-FlashX, GLM-4-Plus, GLM-4-Long, GLM-4-Air, and GLM-4-AirX, all MIT-licensed for commercial use.

### Languages
- Any

### Notes
- Exceptional coding performance: 64.2% on SWE-bench Verified, 37.5% on TerminalBench, beats GPT-4.1 and Claude 4 Opus.
- Real-world coding wins: 80.8% win rate against Qwen3 Coder in practical coding challenges.
- MoE architecture: GLM-4.5 has 355B total parameters (32B active), GLM-4.5-Air has 106B total (12B active).
- Hardware efficient: Runs on just 8x Nvidia H20 GPUs, half the requirement of comparable models.
- Real-time code generation: Direct generation of HTML, CSS, JS, and SVG within conversations.
- Agent capabilities: GLM-4-32B variant enhanced for tool usage, web search, and code generation.
- Multiple variants: Flash, FlashX, Plus, Long, Air, and AirX versions for different use cases.
- Free tier available: GLM-4-Flash and GLM-4.5-Flash optimized for free coding and reasoning.
- MIT licensed: Open source with full commercial use rights, self-hosting, and custom training.
- Z.ai/Zhipu AI: Developed by Chinese AI startup, CEO Zhang Peng.
- Released August 2025 with strong benchmark results.

### Last Update
- 2025-08

## Licensing

### Opensource
- Yes

### License
- MIT

### Free Trial
- Yes
